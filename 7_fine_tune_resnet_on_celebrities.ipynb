{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator, \n",
    "    DirectoryIterator\n",
    ")\n",
    "from google.cloud import aiplatform, storage\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import sys\n",
    "from loguru import logger\n",
    "\n",
    "sys.path.insert(0, \"./backend\")\n",
    "import recognition\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID=\"celebrity-face-recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "path_to_saved_model = pathlib.Path(\"./backend/model\")\n",
    "\n",
    "train=False\n",
    "if not train:\n",
    "    assert path_to_saved_model.exists(), f\"Could not find {path_to_saved_model}\"\n",
    "    assert path_to_saved_model.is_dir(), f\"{path_to_saved_model} is not a directory\"\n",
    "    model = recognition.load_local_model(path_to_saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download the pre-trained ResNet 50 model from TensorFlow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(*recognition.DEFAULT_IMAGE_SIZE, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, figure out how many celebrities we have (just the number of directories inside the `Celebrity Faces Dataset`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 celebrities in the dataset.\n"
     ]
    }
   ],
   "source": [
    "path_to_celebrity_dataset = pathlib.Path(\"./backend/Celebrity Faces Dataset/\")\n",
    "assert path_to_celebrity_dataset.exists(), f\"Could not find {path_to_celebrity_dataset}.\"\n",
    "number_celebrities = len(list(path_to_celebrity_dataset.iterdir()))\n",
    "print(f\"There are {number_celebrities} celebrities in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll instantiate a model on top of our pre-trained ResNet 50 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 17)                34833     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23622545 (90.11 MB)\n",
      "Trainable params: 23569425 (89.91 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(number_celebrities, activation=\"softmax\"),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use TensorFlow utilities (`ImageDataGenerator`) to load and preprocess the celebrity images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "target_image_size = recognition.DEFAULT_IMAGE_SIZE\n",
    "\n",
    "training_data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "training_data_streamer: DirectoryIterator = training_data_generator.flow_from_directory(\n",
    "    path_to_celebrity_dataset,\n",
    "    target_size=target_image_size,\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll compile our model, using the Adam optimizer, and the categorical crossentropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 114s 2s/step - loss: 2.2561 - accuracy: 0.3028\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 110s 2s/step - loss: 0.9090 - accuracy: 0.7183\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 111s 2s/step - loss: 0.4521 - accuracy: 0.8767\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.2322 - accuracy: 0.9439\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 109s 2s/step - loss: 0.1618 - accuracy: 0.9633\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 137s 2s/step - loss: 0.1127 - accuracy: 0.9717\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 168s 3s/step - loss: 0.0852 - accuracy: 0.9806\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 128s 2s/step - loss: 0.0757 - accuracy: 0.9822\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 122s 2s/step - loss: 0.0575 - accuracy: 0.9850\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 143s 3s/step - loss: 0.0514 - accuracy: 0.9856\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "    training_data_streamer,\n",
    "    epochs=training_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use this fine-tuned model to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-29 12:14:40.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecognition\u001b[0m:\u001b[36mmake_prediction\u001b[0m:\u001b[36m79\u001b[0m - \u001b[1mInput image: <PIL.Image.Image image mode=RGB size=112x112 at 0x2C8E753D0>\u001b[0m\n",
      "\u001b[32m2023-12-29 12:14:40.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecognition\u001b[0m:\u001b[36mmake_prediction\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mImage array shape: (112, 112, 3)\u001b[0m\n",
      "\u001b[32m2023-12-29 12:14:40.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecognition\u001b[0m:\u001b[36mmake_prediction\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mAfter expanding dimensions: (1, 112, 112, 3)\u001b[0m\n",
      "\u001b[32m2023-12-29 12:14:40.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecognition\u001b[0m:\u001b[36mmake_prediction\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mAfter preprocessing: (1, 112, 112, 3)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-29 12:14:46.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecognition\u001b[0m:\u001b[36mmake_prediction\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mPredicted celebrity index: 16\u001b[0m\n",
      "\u001b[32m2023-12-29 12:14:46.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecognition\u001b[0m:\u001b[36mmake_prediction\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mUsing idx_to_celebrity_name mapping: {'0': 'Angelina Jolie', '1': 'Brad Pitt', '2': 'Denzel Washington', '3': 'Hugh Jackman', '4': 'Jennifer Lawrence', '5': 'Johnny Depp', '6': 'Kate Winslet', '7': 'Leonardo DiCaprio', '8': 'Megan Fox', '9': 'Natalie Portman', '10': 'Nicole Kidman', '11': 'Robert Downey Jr', '12': 'Sandra Bullock', '13': 'Scarlett Johansson', '14': 'Tom Cruise', '15': 'Tom Hanks', '16': 'Will Smith'}\u001b[0m\n",
      "\u001b[32m2023-12-29 12:14:46.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrecognition\u001b[0m:\u001b[36mmake_prediction\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mPredicted celebrity name: Will Smith\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted celebrity: Will Smith\n"
     ]
    }
   ],
   "source": [
    "example_image = recognition.load_image_from_file(\n",
    "    image_path=path_to_celebrity_dataset / \"Will Smith/001_beebcee2.jpg\"\n",
    ")\n",
    "\n",
    "idx_to_celebrity_name = {str(v): k for k, v in training_data_streamer.class_indices.items()}\n",
    "\n",
    "predicted_celebrity = recognition.make_prediction(example_image, model, idx_to_celebrity_name)\n",
    "print(f\"Predicted celebrity: {predicted_celebrity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our fine-tuned ResNet 50 to a `model` directory in the `backend` folder in the SavedModel format, making sure to attach the index to celebrity name dictionary as an asset inside the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: backend/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: backend/model/assets\n"
     ]
    }
   ],
   "source": [
    "path_to_idx_to_celebrity_mapping = path_to_saved_model.parent / \"idx_to_celebrity_name.json\"\n",
    "with open(path_to_idx_to_celebrity_mapping, 'w') as f:\n",
    "    json.dump(idx_to_celebrity_name, f)\n",
    "asset = tf.saved_model.Asset(path_to_idx_to_celebrity_mapping)\n",
    "\n",
    "model.asset = asset\n",
    "model.save(path_to_saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is an example of how you'd load the model back in, along with its dictionary of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'Angelina Jolie', '1': 'Brad Pitt', '2': 'Denzel Washington', '3': 'Hugh Jackman', '4': 'Jennifer Lawrence', '5': 'Johnny Depp', '6': 'Kate Winslet', '7': 'Leonardo DiCaprio', '8': 'Megan Fox', '9': 'Natalie Portman', '10': 'Nicole Kidman', '11': 'Robert Downey Jr', '12': 'Sandra Bullock', '13': 'Scarlett Johansson', '14': 'Tom Cruise', '15': 'Tom Hanks', '16': 'Will Smith'}\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(path_to_saved_model)\n",
    "with open(loaded_model.asset.asset_path.numpy(), 'r') as f:\n",
    "    loaded_idx_to_celebrity_name= json.load(f)\n",
    "\n",
    "print(loaded_idx_to_celebrity_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 POST https://storage.googleapis.com/upload/storage/v1/b/celebrity-face-detection-model-bucket/o?uploadType=multipart: {\n  \"error\": {\n    \"code\": 404,\n    \"message\": \"The specified bucket does not exist.\",\n    \"errors\": [\n      {\n        \"message\": \"The specified bucket does not exist.\",\n        \"domain\": \"global\",\n        \"reason\": \"notFound\"\n      }\n    ]\n  }\n}\n: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidResponse\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/cloud/storage/blob.py:2607\u001b[0m, in \u001b[0;36mBlob._prep_and_do_upload\u001b[0;34m(self, file_obj, rewind, size, content_type, num_retries, client, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2607\u001b[0m     created_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredefined_acl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2623\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(created_json)\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/cloud/storage/blob.py:2413\u001b[0m, in \u001b[0;36mBlob._do_upload\u001b[0;34m(self, client, stream, content_type, size, num_retries, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m _MAX_MULTIPART_SIZE:\n\u001b[0;32m-> 2413\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_multipart_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2417\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredefined_acl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/cloud/storage/blob.py:1926\u001b[0m, in \u001b[0;36mBlob._do_multipart_upload\u001b[0;34m(self, client, stream, content_type, size, num_retries, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[1;32m   1922\u001b[0m upload\u001b[38;5;241m.\u001b[39m_retry_strategy \u001b[38;5;241m=\u001b[39m _api_core_retry_to_resumable_media_retry(\n\u001b[1;32m   1923\u001b[0m     retry, num_retries\n\u001b[1;32m   1924\u001b[0m )\n\u001b[0;32m-> 1926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mupload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransmit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/resumable_media/requests/upload.py:153\u001b[0m, in \u001b[0;36mMultipartUpload.transmit\u001b[0;34m(self, transport, data, metadata, content_type, timeout)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_and_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriable_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_strategy\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/resumable_media/requests/_request_helpers.py:155\u001b[0m, in \u001b[0;36mwait_and_retry\u001b[0;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _CONNECTION_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/resumable_media/requests/upload.py:149\u001b[0m, in \u001b[0;36mMultipartUpload.transmit.<locals>.retriable_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m result \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    146\u001b[0m     method, url, data\u001b[38;5;241m=\u001b[39mpayload, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    147\u001b[0m )\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/resumable_media/_upload.py:125\u001b[0m, in \u001b[0;36mUploadBase._process_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[43m_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_status_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/resumable_media/_helpers.py:108\u001b[0m, in \u001b[0;36mrequire_status_code\u001b[0;34m(response, status_codes, get_status_code, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m         callback()\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m common\u001b[38;5;241m.\u001b[39mInvalidResponse(\n\u001b[1;32m    109\u001b[0m         response,\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest failed with status code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    111\u001b[0m         status_code,\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected one of\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;241m*\u001b[39mstatus_codes\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status_code\n",
      "\u001b[0;31mInvalidResponse\u001b[0m: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m bucket_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcelebrity-face-detection-model-bucket\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m model_cloud_storage_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mupload_dir_to_gcs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_to_saved_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcs_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_cloud_storage_uri\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mupload_dir_to_gcs\u001b[0;34m(local_path, bucket_name, gcs_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m local_file\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m     18\u001b[0m     blob \u001b[38;5;241m=\u001b[39m bucket\u001b[38;5;241m.\u001b[39mblob(remote_path)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mblob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_from_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     uploaded_objects\u001b[38;5;241m.\u001b[39mappend(local_file)\n\u001b[1;32m     22\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgcs_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/cloud/storage/blob.py:2929\u001b[0m, in \u001b[0;36mBlob.upload_from_filename\u001b[0;34m(self, filename, content_type, num_retries, client, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupload_from_filename\u001b[39m(\n\u001b[1;32m   2808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2809\u001b[0m     filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2820\u001b[0m     retry\u001b[38;5;241m=\u001b[39mDEFAULT_RETRY_IF_GENERATION_SPECIFIED,\n\u001b[1;32m   2821\u001b[0m ):\n\u001b[1;32m   2822\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Upload this blob's contents from the content of a named file.\u001b[39;00m\n\u001b[1;32m   2823\u001b[0m \n\u001b[1;32m   2824\u001b[0m \u001b[38;5;124;03m    The content type of the upload will be determined in order\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;124;03m        are respected.\u001b[39;00m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2929\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_filename_and_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredefined_acl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_acl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_generation_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_generation_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_metageneration_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/cloud/storage/blob.py:2799\u001b[0m, in \u001b[0;36mBlob._handle_filename_and_upload\u001b[0;34m(self, filename, content_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_obj:\n\u001b[1;32m   2798\u001b[0m     total_bytes \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfstat(file_obj\u001b[38;5;241m.\u001b[39mfileno())\u001b[38;5;241m.\u001b[39mst_size\n\u001b[0;32m-> 2799\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prep_and_do_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2802\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_bytes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2803\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2804\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/cloud/storage/blob.py:2625\u001b[0m, in \u001b[0;36mBlob._prep_and_do_upload\u001b[0;34m(self, file_obj, rewind, size, content_type, num_retries, client, predefined_acl, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[1;32m   2623\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(created_json)\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mInvalidResponse \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m-> 2625\u001b[0m     \u001b[43m_raise_from_invalid_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/face-detection/env/lib/python3.11/site-packages/google/cloud/storage/blob.py:4791\u001b[0m, in \u001b[0;36m_raise_from_invalid_response\u001b[0;34m(error)\u001b[0m\n\u001b[1;32m   4787\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(error)\n\u001b[1;32m   4789\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 4791\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_status(response\u001b[38;5;241m.\u001b[39mstatus_code, message, response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 POST https://storage.googleapis.com/upload/storage/v1/b/celebrity-face-detection-model-bucket/o?uploadType=multipart: {\n  \"error\": {\n    \"code\": 404,\n    \"message\": \"The specified bucket does not exist.\",\n    \"errors\": [\n      {\n        \"message\": \"The specified bucket does not exist.\",\n        \"domain\": \"global\",\n        \"reason\": \"notFound\"\n      }\n    ]\n  }\n}\n: ('Request failed with status code', 404, 'Expected one of', <HTTPStatus.OK: 200>)"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_dir_to_gcs(local_path, bucket_name, gcs_path):\n",
    "  \"\"\"Upload local directory to GCS\"\"\"\n",
    "  if isinstance(local_path, str):\n",
    "    local_path = pathlib.Path(local_path)\n",
    "  if isinstance(gcs_path, str):\n",
    "    gcs_path = pathlib.Path(gcs_path)\n",
    "\n",
    "  uploaded_objects = []\n",
    "\n",
    "  client = storage.Client(project=PROJECT_ID)\n",
    "  bucket = client.bucket(bucket_name)\n",
    "\n",
    "  for local_file in local_path.glob(\"**/*\"):\n",
    "    remote_path = \"/\".join(local_file.parts[2:])\n",
    "    if not local_file.is_dir():\n",
    "      blob = bucket.blob(remote_path)\n",
    "      blob.upload_from_filename(local_file)\n",
    "      uploaded_objects.append(local_file)\n",
    "  \n",
    "  logger.info(f\"Uploaded {local_path} to {gcs_path} in {bucket_name}\")\n",
    "  logger.info(f\"Uploaded {len(uploaded_objects)} objects\")\n",
    "\n",
    "bucket_name = \"celebrity-face-detection-model-bucket\"\n",
    "model_cloud_storage_uri = f\"gs://{bucket_name}/model\"\n",
    "\n",
    "upload_dir_to_gcs(\n",
    "    local_path=path_to_saved_model,\n",
    "    bucket_name=bucket_name,\n",
    "    gcs_path=model_cloud_storage_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=\"us-east4\")\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=\"celebrity-recognition\",\n",
    "    artifact_uri=model_cloud_storage_uri,\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-12:latest\",\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=\"celebrity_recognition\",\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-7DY3twuc-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
